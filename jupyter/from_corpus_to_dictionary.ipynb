{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아하 True\n",
      "ㅋ True\n",
      "ㅠ True\n",
      "알랄ㄹ랴 True\n",
      "1호점 True\n",
      "a False\n",
      "(주) False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "korean_pattern = re.compile('[ㄱ-ㅎㅏ-ㅣ가-힣0-9]+')\n",
    "is_korean = lambda s:korean_pattern.match(s) is not None\n",
    "\n",
    "for word in '아하 ㅋ ㅠ 알랄ㄹ랴 1호점 a (주)'.split():\n",
    "    print(word, is_korean(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "posdic = defaultdict(lambda: defaultdict(int))\n",
    "with open('../data/processed/tagger/fulltag.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            tokens = line.strip().split()\n",
    "            tokens = [token.split('/') for token in tokens]\n",
    "            tokens = [token for token in tokens if len(token) == 2]\n",
    "            for word, pos in tokens:\n",
    "                if not is_korean(word):\n",
    "                    continue\n",
    "                posdic[pos][word] += 1\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNG has 90250 words\n",
      "NNP has 59915 words\n",
      "VV has 6600 words\n",
      "MAG has 6312 words\n",
      "XR has 2372 words\n",
      "EF has 1650 words\n",
      "VA has 1612 words\n",
      "EC has 1484 words\n",
      "IC has 1197 words\n",
      "NNB has 553 words\n",
      "NR has 421 words\n",
      "NP has 277 words\n",
      "MAJ has 258 words\n",
      "MM has 228 words\n",
      "ETM has 145 words\n",
      "JX has 136 words\n",
      "VX has 125 words\n",
      "XSN has 124 words\n",
      "JKB has 121 words\n",
      "XPN has 77 words\n",
      "EP has 74 words\n",
      "JC has 51 words\n",
      "XSV has 24 words\n",
      "JKS has 20 words\n",
      "XSA has 20 words\n",
      "JKV has 16 words\n",
      "ETN has 16 words\n",
      "VCP has 13 words\n",
      "JKG has 10 words\n",
      "JKQ has 10 words\n",
      "VCN has 9 words\n",
      "JKO has 8 words\n",
      "JKC has 5 words\n",
      "NG has 3 words\n",
      "NNG\" has 3 words\n",
      "NNGG has 2 words\n",
      "VA\" has 1 words\n",
      "MAC has 1 words\n",
      "VSV has 1 words\n",
      "VX\" has 1 words\n",
      "V has 1 words\n",
      "MAAG has 1 words\n",
      "JKBB has 1 words\n",
      "NN has 1 words\n",
      "JG has 1 words\n",
      "JKSS has 1 words\n",
      "NNg has 1 words\n",
      "MMM has 1 words\n",
      "EEC has 1 words\n"
     ]
    }
   ],
   "source": [
    "for pos in sorted(posdic, key=lambda x:-len(posdic[x])):\n",
    "    print('%s has %d words' % (pos, len(posdic[pos])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagset = [\n",
    "    'NNG', 'NNP', 'VV', 'MAG', 'XR',\n",
    "    'EF', 'EC', 'VA', 'IC', 'NNB',\n",
    "    'NR', 'NP', 'MAJ', 'MM', 'ETM',\n",
    "    'JX', 'VX', 'JKB', 'XSN', 'XPN',\n",
    "    'EP', 'JC', 'XSV', 'XSA', 'JKS',\n",
    "    'ETN', 'JKV', 'VCP', 'JKO', 'JKQ',\n",
    "    'JKG', 'VCN', 'JKC'\n",
    "]\n",
    "\n",
    "for pos in tagset:\n",
    "    with open('../dictionary/sejong/{}.txt'.format(pos), 'w', encoding='utf-8') as f:\n",
    "        for word, count in sorted(posdic[pos].items()):\n",
    "            f.write('{} {}\\n'.format(word, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapper = {\n",
    "  'NNG': 'Noun',\n",
    "  'NNP': 'Noun',\n",
    "  'VV': 'Verb',\n",
    "  'MAG': 'Adverb',\n",
    "  'XR': 'Noun',\n",
    "  'EF': 'Eomi',\n",
    "  'EC': 'Eomi',\n",
    "  'VA': 'Adjective',\n",
    "  'IC': 'Exclamation',\n",
    "  'NNB': 'Noun',\n",
    "  'NR': 'Noun',\n",
    "  'NP': 'Noun',\n",
    "  'MAJ': 'Adverb',\n",
    "  'MM': 'Determiner',\n",
    "  'ETM': 'Eomi',\n",
    "  'JX': 'Josa',\n",
    "  'VX': 'Adjective',\n",
    "  'JKB': 'Josa',\n",
    "  'XSN': 'Eomi',\n",
    "  'XPN': 'Determiner',\n",
    "  'EP': 'Eomi',\n",
    "  'JC': 'Josa',\n",
    "  'XSV': 'Noun',\n",
    "  'XSA': 'Noun',\n",
    "  'JKS': 'Josa',\n",
    "  'ETN': 'Eomi',\n",
    "  'JKV': 'Josa',\n",
    "  'VCP': 'Noun',\n",
    "  'JKO': 'Josa',\n",
    "  'JKQ': 'Josa',\n",
    "  'JKG': 'Josa',\n",
    "  'VCN': 'Noun',\n",
    "  'JKC': 'Josa'\n",
    "}\n",
    "\n",
    "posdic_ = defaultdict(lambda: defaultdict(int))\n",
    "for pos in tagset:\n",
    "    pos_ = mapper[pos]\n",
    "    for word, count in posdic[pos].items():\n",
    "        posdic_[pos_][word] += count \n",
    "\n",
    "for pos in posdic_:\n",
    "    with open('../dictionary/simplified/{}.txt'.format(pos), 'w', encoding='utf-8') as f:\n",
    "        for word, count in sorted(posdic_[pos].items()):\n",
    "            f.write('{} {}\\n'.format(word, count))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [lovit]",
   "language": "python",
   "name": "Python [lovit]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
