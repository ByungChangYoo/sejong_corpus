{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세종말뭉치의 통계를 계산하기 위하여 만든 Jupyter notebook 파일입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "fnames = glob('../data/processed/cd1/02_말뭉치/현대/*/*/형태분석_말뭉치/*.txt')\n",
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['뭐', '타고', '가?'] ['뭐/NP', '타/VV+고/EC', '가/VV+ㅏ/EF+?/SF']\n",
      "['지하철.'] ['지하철/NNG+./SF']\n",
      "['기차?'] ['기차/NNG+?/SF']\n",
      "['아침에', '몇', '시에', '타고', '가는데?'] ['아침/NNG+에/JKB', '몇/MM', '시/NNB+에/JKB', '타/VV+고/EC', '가/VV+는데/EF+?/SF']\n"
     ]
    }
   ],
   "source": [
    "class Documents:\n",
    "    def __init__(self, fnames, yield_text=True, yield_tag=True):\n",
    "        self.fnames = fnames\n",
    "        self.yield_text = yield_text\n",
    "        self.yield_tag = yield_tag\n",
    "    def __iter__(self):\n",
    "        if self.yield_text or self.yield_tag:\n",
    "            for fname in self.fnames:\n",
    "                with open(fname, encoding='utf-8') as f:\n",
    "                    for row in f:\n",
    "                        sent, tag = row.strip().split('\\t')\n",
    "                        if self.yield_text and self.yield_tag:\n",
    "                            yield (sent.split(), tag.split())\n",
    "                        elif self.yield_text:\n",
    "                            yield sent.split()\n",
    "                        elif self.yield_tag:\n",
    "                            yield tag.split()\n",
    "                            \n",
    "docs = Documents(fnames, yield_text=True, yield_tag=True)\n",
    "for i, (words, tags) in enumerate(docs):\n",
    "    if i > 3: break\n",
    "    print(words, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num files = 200\n",
      "num sents = 216723\n"
     ]
    }
   ],
   "source": [
    "fnames = glob('../data/processed/cd1/02_말뭉치/현대/구어/*/형태분석_말뭉치/*.txt')\n",
    "print('num files = %d' % len(fnames))\n",
    "\n",
    "docs = Documents(fnames, yield_text=True, yield_tag=False)\n",
    "for n_sent, _ in enumerate(docs):\n",
    "    continue\n",
    "print('num sents = %d' % (n_sent+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num files = 279\n",
      "num sents = 837843\n"
     ]
    }
   ],
   "source": [
    "fnames = glob('../data/processed/cd1/02_말뭉치/현대/문어/*/형태분석_말뭉치/*.txt')\n",
    "print('num files = %d' % len(fnames))\n",
    "\n",
    "docs = Documents(fnames, yield_text=True, yield_tag=False)\n",
    "for n_sent, _ in enumerate(docs):\n",
    "    continue\n",
    "print('num sents = %d' % (n_sent+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of eojeol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num eojeols = 10807777\n",
      "unique num eojeols = 1560437\n",
      "Top 50 eojeols\n",
      "[('그', 81457),\n",
      " ('수', 68306),\n",
      " ('있다.', 56845),\n",
      " ('있는', 55802),\n",
      " ('이', 47680),\n",
      " ('한', 39459),\n",
      " ('것이다.', 37810),\n",
      " ('하는', 25381),\n",
      " ('것은', 24816),\n",
      " ('것이', 24642),\n",
      " ('그러나', 24511),\n",
      " ('할', 22909),\n",
      " ('나는', 22162),\n",
      " ('한다.', 21743),\n",
      " ('같은', 21198),\n",
      " ('있었다.', 20835),\n",
      " ('대한', 20529),\n",
      " ('또', 19782),\n",
      " ('그런', 19575),\n",
      " ('그리고', 18481),\n",
      " ('안', 17729),\n",
      " ('더', 17374),\n",
      " ('것을', 16830),\n",
      " ('우리', 16461),\n",
      " ('하고', 16312),\n",
      " ('그는', 15906),\n",
      " ('다른', 15238),\n",
      " ('때', 14866),\n",
      " ('없는', 14781),\n",
      " ('했다.', 14724),\n",
      " ('등', 14473),\n",
      " ('이런', 14375),\n",
      " ('두', 13645),\n",
      " ('내가', 13533),\n",
      " ('것', 13433),\n",
      " ('잘', 13230),\n",
      " ('다시', 13112),\n",
      " ('어떤', 12771),\n",
      " ('때문에', 12745),\n",
      " ('내', 12236),\n",
      " ('다', 11823),\n",
      " ('그의', 11120),\n",
      " ('것으로', 11046),\n",
      " ('없다.', 10544),\n",
      " ('이렇게', 10499),\n",
      " ('게', 10452),\n",
      " ('위해', 10374),\n",
      " ('가장', 10309),\n",
      " ('아니라', 10125),\n",
      " ('있을', 9922)]\n"
     ]
    }
   ],
   "source": [
    "fnames = glob('../data/processed/cd1/02_말뭉치/현대/*/*/형태분석_말뭉치/*.txt')\n",
    "print('num files = %d' % len(fnames))\n",
    "\n",
    "from collections import Counter\n",
    "docs = Documents(fnames, yield_text=True, yield_tag=False)\n",
    "counter = Counter((eojeol for sent in docs for eojeol in sent))\n",
    "        \n",
    "print('num eojeols = %d' % (sum(counter.values())))\n",
    "print('unique num eojeols = %d' % (len(counter)))\n",
    "\n",
    "print('Top 50 eojeols')\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(sorted(counter.items(), key=lambda x:x[1], reverse=True)[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of (word,tag) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num files = 479\n",
      "num (word,tag) = 24464414\n",
      "unique (word,tag) = 233023\n",
      "Top 50 (word,tag)\n",
      "[('./SF', 844440),\n",
      " ('의/JKG', 520895),\n",
      " ('을/JKO', 518468),\n",
      " ('ᆫ/ETM', 504474),\n",
      " ('다/EF', 488114),\n",
      " ('하/XSV', 458052),\n",
      " ('이/VCP', 450704),\n",
      " (',/SP', 447595),\n",
      " ('에/JKB', 416730),\n",
      " ('이/JKS', 368869),\n",
      " ('는/ETM', 355747),\n",
      " ('고/EC', 334472),\n",
      " ('는/JX', 331517),\n",
      " ('를/JKO', 299948),\n",
      " ('었/EP', 262254),\n",
      " ('은/JX', 260232),\n",
      " ('가/JKS', 245540),\n",
      " ('았/EP', 219846),\n",
      " ('하/XSA', 213519),\n",
      " ('것/NNB', 213480),\n",
      " ('어/EC', 212189),\n",
      " ('아/EC', 197251),\n",
      " ('도/JX', 176239),\n",
      " ('ᆯ/ETM', 172974),\n",
      " ('들/XSN', 172217),\n",
      " ('\"/SS', 168212),\n",
      " ('하/VV', 161492),\n",
      " ('으로/JKB', 155012),\n",
      " ('에서/JKB', 145061),\n",
      " (\"'/SS\", 130833),\n",
      " ('게/EC', 129173),\n",
      " ('있/VV', 129074),\n",
      " ('있/VX', 127462),\n",
      " ('적/XSN', 126644),\n",
      " ('로/JKB', 113025),\n",
      " ('되/XSV', 106876),\n",
      " ('은/ETM', 102896),\n",
      " ('지/EC', 99173),\n",
      " ('ᆫ다/EF', 97583),\n",
      " ('기/ETN', 96926),\n",
      " (')/SS', 96347),\n",
      " ('(/SS', 94872),\n",
      " ('수/NNB', 87306),\n",
      " ('되/VV', 85798),\n",
      " ('그/MM', 85468),\n",
      " ('하/VX', 84812),\n",
      " ('없/VA', 71620),\n",
      " ('?/SF', 71204),\n",
      " ('않/VX', 70039),\n",
      " ('과/JC', 69970)]\n"
     ]
    }
   ],
   "source": [
    "fnames = glob('../data/processed/cd1/02_말뭉치/현대/*/*/형태분석_말뭉치/*.txt')\n",
    "print('num files = %d' % len(fnames))\n",
    "\n",
    "from collections import Counter\n",
    "docs = Documents(fnames, yield_text=False, yield_tag=True)\n",
    "counter_wordtag = Counter((w for sent in docs for eojeol in sent for w in eojeol.split('+')))\n",
    "        \n",
    "print('num (word,tag) = %d' % (sum(counter_wordtag.values())))\n",
    "print('unique (word,tag) = %d' % (len(counter_wordtag)))\n",
    "\n",
    "print('Top 50 (word,tag)')\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(sorted(counter_wordtag.items(), key=lambda x:x[1], reverse=True)[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write [token, wordtag, frequency] table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique (eojeol,word,tag) = 1642217\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def to_eojeol_wordtag(sent, tags):\n",
    "    return [(word, tag) for word, tag in zip(sent, tags)]\n",
    "docs = Documents(fnames, yield_text=True, yield_tag=True)\n",
    "counter_pair = Counter((pair for sent, tags in docs for pair in to_eojeol_wordtag(sent,tags)))\n",
    "print('unique (eojeol,word,tag) = %d' % (len(counter_pair)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/processed/lr/tokentable.txt', 'w', encoding='utf-8') as f:\n",
    "    for (eojeol, wordtag), freq in sorted(counter_pair.items(), key=lambda x:x[1], reverse=True):\n",
    "        f.write('%s\\t%s\\t%d\\n' % (eojeol, wordtag, freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokentable line grep\n",
    "\n",
    "Jupyter notebook 에서 query가 들어있는 단어를 읽을 수 있도록 likesearch를 만들어 두었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likesearch(query, topk=100):\n",
    "    n_count = 0\n",
    "    with open('../data/processed/lr/tokentable.txt', encoding='utf-8') as f:\n",
    "        for row in f:\n",
    "            if n_count >= topk: break\n",
    "            if query in row:\n",
    "                n_count += 1\n",
    "                print(row.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지난해\t지난해/NNG\t1311\n",
      "지난해\t지나/VV+ᆫ/ETM+해/NNG\t55\n",
      "지난해의\t지난해/NNG+의/JKG\t54\n",
      "지난해보다\t지난해/NNG+보다/JKB\t52\n",
      "지난해부터\t지난해/NNG+부터/JX\t52\n",
      "지난해에\t지난해/NNG+에/JKB\t50\n",
      "\"지난해\t\"/SS+지난해/NNG\t48\n",
      "지난해에는\t지난해/NNG+에/JKB+는/JX\t34\n",
      "지난해와\t지난해/NNG+와/JKB\t22\n",
      "지난해까지\t지난해/NNG+까지/JX\t16\n",
      "지난해말\t지난해/NNG+말/NNB\t13\n",
      "지난해에도\t지난해/NNG+에/JKB+도/JX\t10\n",
      "지난해말의\t지난해/NNG+말/NNB+의/JKG\t9\n",
      "지난해엔\t지난해/NNG+에/JKB+ᆫ/JX\t8\n",
      "지난해는\t지난해/NNG+는/JX\t6\n",
      "지난해\t지난/MM+해/NNG\t6\n",
      "지난해와\t지난해/NNG+와/JC\t5\n",
      "지난해부터는\t지난해/NNG+부터/JX+는/JX\t5\n",
      "\"지난해에는\t\"/SS+지난해/NNG+에/JKB+는/JX\t4\n",
      "지난해를\t지난해/NNG+를/JKO\t4\n",
      "지난해만\t지난해/NNG+만/JX\t4\n",
      "지난해에만\t지난해/NNG+에/JKB+만/JX\t4\n",
      "지난해까지만\t지난해/NNG+까지/JX+만/JX\t3\n",
      "지난해,\t지난해/NNG+,/SP\t3\n",
      "지난해까지는\t지난해/NNG+까지/JX+는/JX\t3\n",
      "지지난해\t지지난해/NNG\t3\n",
      "지난해(10.3%)와\t지난해/NNG+(/SS+10/SN+./SP+3/SN+%/SW+)/SS+와/JKB\t2\n",
      "지난해에도\t지나/VV+ᆫ/ETM+해/NNG+에/JKB+도/JX\t2\n",
      "지난해까지\t지나/VV+ᆫ/ETM+해/NNG+까지/JX\t2\n",
      "지난해에,\t지난해/NNG+에/JKB+,/SP\t2\n"
     ]
    }
   ],
   "source": [
    "likesearch('지난해', topk=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
