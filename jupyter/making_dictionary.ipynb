{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. N + [RJ, RA, RV] 명사 오른쪽에는 “조사 / 형용사 / 동사\"가 올 수 있다. \n",
    "\n",
    "1. 동/형용사 중에는 L/R이 안되는 경우가 있다. 이 경우에는 사전으로 외워두는게 낫다\n",
    "    - 간 = 가/동사 + ㄴ/어미\n",
    "\n",
    "사전을 만들 tag 종류는 다음과 같다. \n",
    "    \n",
    "    ## 품사 사전\n",
    "    Noun\n",
    "    Adjective / Verb (어절이 단어임)\n",
    "    Josa\n",
    "    Determiner\n",
    "    Adverb\n",
    "    Exclamation\n",
    "    Eomi\n",
    "    \n",
    "    ## LR 사전\n",
    "    RVerb / RAdjective (명사 왼쪽에 등장하여 명사랑 결합되는 경우들: 이해했다)\n",
    "    Josa\n",
    "    Eomi / LVerb/LAdjective L-R 구조는 out of vocabulary 용언에 대한 힌트가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\tmorphomes\tpos\tlr\tcount\n",
      "그\t그/MM\t그/Determiner\t그/Determiner\t80726\n",
      "수\t수/NNB\t수/Noun\t수/Noun\t67991\n",
      "이\t이/MM\t이/Determiner\t이/Determiner\t45777\n",
      "것이다.\t것/NNB+이/VCP+다/EF+./SF\t것/Noun+이/Adjective+다/Eomi\t것/Noun+이다/Adjective\t37808\n",
      "있다.\t있/VX+다/EF+./SF\t있/Verb+다/Eomi\t있/Verb+다/Eomi\t30548\n",
      "한\t한/MM\t한/Determiner\t한/Determiner\t30536\n",
      "있는\t있/VX+는/ETM\t있/Verb+는/Eomi\t있/Verb+는/Eomi\t28946\n",
      "있다.\t있/VV+다/EF+./SF\t있/Verb+다/Eomi\t있/Verb+다/Eomi\t26195\n",
      "있는\t있/VV+는/ETM\t있/Verb+는/Eomi\t있/Verb+는/Eomi\t25045\n",
      "것은\t것/NNB+은/JX\t것/Noun+은/Josa\t것/Noun+은/Josa\t24816\n",
      "그러나\t그러나/MAJ\t그러나/Adverb\t그러나/Adverb\t24498\n",
      "같은\t같/VA+은/ETM\t같/Adjective+은/Eomi\t같/Adjective+은/Eomi\t21197\n",
      "나는\t나/NP+는/JX\t나/Noun+는/Josa\t나/Noun+는/Josa\t21182\n",
      "대한\t대하/VV+ᆫ/ETM\t대하/Verb+ᆫ/Eomi\t대한/Verb+/Eomi\t19874\n",
      "그런\t그런/MM\t그런/Determiner\t그런/Determiner\t18999\n",
      "것이\t것/NNB+이/JKS\t것/Noun+이/Josa\t것/Noun+이/Josa\t18870\n",
      "그리고\t그리고/MAJ\t그리고/Adverb\t그리고/Adverb\t18322\n",
      "하는\t하/VV+는/ETM\t하/Verb+는/Eomi\t하/Verb+는/Eomi\t17952\n",
      "더\t더/MAG\t더/Adverb\t더/Adverb\t17355\n",
      "안\t안/MAG\t안/Adverb\t안/Adverb\t17330\n",
      "것을\t것/NNB+을/JKO\t것/Noun+을/Josa\t것/Noun+을/Josa\t16829\n",
      "우리\t우리/NP\t우리/Noun\t우리/Noun\t16418\n",
      "또\t또/MAG\t또/Adverb\t또/Adverb\t16058\n",
      "그는\t그/NP+는/JX\t그/Noun+는/Josa\t그/Noun+는/Josa\t15906\n",
      "때\t때/NNG\t때/Noun\t때/Noun\t14854\n",
      "없는\t없/VA+는/ETM\t없/Adjective+는/Eomi\t없/Adjective+는/Eomi\t14780\n",
      "있었다.\t있/VX+었/EP+다/EF+./SF\t있/Verb+었다/Eomi\t있/Verb+었다/Eomi\t14622\n",
      "이런\t이런/MM\t이런/Determiner\t이런/Determiner\t14344\n",
      "등\t등/NNB\t등/Noun\t등/Noun\t14314\n"
     ]
    }
   ],
   "source": [
    "with open('../data/processed/lr/tokentable_simple_lr.txt', encoding='utf-8') as f:\n",
    "    for i, _ in enumerate(f):\n",
    "        if i >= 30: break\n",
    "        print(_.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def is_korean(s):\n",
    "    for c in s:\n",
    "        if not (44032 <= ord(c) <= 55203):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "dictionary_pos = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "dictionary_r = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "dictionary_lv = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "dictionary_stem = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "with open('../data/processed/lr/tokentable_simple_lr.txt', encoding='utf-8') as f:\n",
    "    next(f) # Skip head\n",
    "    for line in f:\n",
    "        _, _, pos, lr, count = line.split('\\t')\n",
    "        count = int(count.strip())\n",
    "        \n",
    "        pos = [p.split('/') for p in pos.split('+')]\n",
    "        lr =  [w.split('/') for w in lr.split('+')]\n",
    "        (ltag, rtag) = (lr[0][1], lr[-1][1])\n",
    "        \n",
    "        for word, tag in pos:\n",
    "            if not is_korean(word):\n",
    "                continue\n",
    "            if (tag == 'Adjective' or tag == 'Verb'):\n",
    "                dictionary_stem[tag][word] += count\n",
    "                continue\n",
    "            dictionary_pos[tag][word] += count\n",
    "        if (ltag == 'Adjective' or ltag == 'Verb'):\n",
    "            word = ''.join([w for w,_ in lr])\n",
    "            if is_korean(word):\n",
    "                dictionary_pos[ltag][word] += count\n",
    "\n",
    "        if len(lr) == 2:\n",
    "            if lr[1][0] and is_korean(lr[1][0]):\n",
    "                dictionary_r[rtag][lr[1][0]] += count\n",
    "            if ltag == 'Adjective' or ltag == 'Verb' and is_korean(lr[0][0]):\n",
    "                dictionary_lv[ltag][lr[0][0]] += count\n",
    "\n",
    "if 'SN' in dictionary_pos:\n",
    "    del dictionary_pos['SN']\n",
    "if 'Determiner' in dictionary_r:    \n",
    "    del dictionary_r['Determiner']\n",
    "if 'Exclamation' in dictionary_r:\n",
    "    del dictionary_r['Exclamation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5, 2, 2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary_pos), len(dictionary_r), len(dictionary_lv),  len(dictionary_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# dictionary_pos\n",
      "Determiner has 205 words\n",
      "Eomi has 17701 words\n",
      "Exclamation has 1193 words\n",
      "Adjective has 25618 words\n",
      "Adverb has 6039 words\n",
      "Noun has 326123 words\n",
      "Josa has 2764 words\n",
      "Verb has 141177 words\n",
      "\n",
      "\n",
      "# dictionary_r\n",
      "Eomi has 17227 words\n",
      "Adjective has 5397 words\n",
      "Adverb has 81 words\n",
      "Josa has 7475 words\n",
      "Verb has 6921 words\n",
      "\n",
      "\n",
      "# dictionary_lv\n",
      "Adjective has 7524 words\n",
      "Verb has 16840 words\n",
      "\n",
      "\n",
      "# dictionary_stem\n",
      "Adjective has 4222 words\n",
      "Verb has 7409 words\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_dictionary(d, head=''):\n",
    "    print(head)\n",
    "    for tag, words in d.items():\n",
    "        print('%s has %d words' % (tag, len(words)))\n",
    "    print('\\n')\n",
    "\n",
    "print_dictionary(dictionary_pos, '# dictionary_pos')\n",
    "print_dictionary(dictionary_r, '# dictionary_r')\n",
    "print_dictionary(dictionary_lv, '# dictionary_lv')\n",
    "print_dictionary(dictionary_stem, '# dictionary_stem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root = '../data/processed/tagger/dictionary/'\n",
    "for folder in ['pos', 'r', 'lv', 'stem']:\n",
    "    dictionary = locals()['dictionary_{}'.format(folder)]\n",
    "    folder = root + folder\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    for tag, worddict in dictionary.items():\n",
    "        with open('{}/{}.txt'.format(folder, tag), 'w', encoding='utf-8') as f:\n",
    "            for word, count in sorted(worddict.items(), key=lambda x:-x[1]):\n",
    "                f.write('{}\\t{}\\n'.format(word, count))\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
